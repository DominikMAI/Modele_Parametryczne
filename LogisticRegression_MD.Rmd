---
title: "Regresja_Logistyczna"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}

library("readxl")
library("car") # funkcja vif()
library("ggplot2") # wykresy - funkcja ggplot()
library("lmtest") # testy diagnostyczne modeli lm

#library("PerformanceAnalytics")
library("ggplot2") # wykresy - funkcja ggplot()
library("pscl") #pseudo-R2 funkcja pR2()
library("pROC") #funkcje roc, auc
set.seed(1257) #set.seed(NULL) --> usunięcie "ziarna"

knitr::opts_chunk$set(echo = TRUE)
```

## Wstep
to do list: \ 
 - interakcje -
 - część samochodow moze byc w rzeczywistosci zarejestrowana na osoby starsze ale uzytkowana przez młodych - którzy powodują kolizje
 -Jeszcze analizuje ale mysle, ze takie zalozenie ma sens, opieramy model na: dochodzie, fakcie bycia rodzicem, wieku i uprzednio otrzymanych punktach karnych. Pozostałe zmienne są pochodnymi tych cech.

### Wczytanie danych
```{r}
dane <- read.csv("./dane/LR_dane_treningowe_testowe.csv")
dane <- dane[, -c(24)]
summary(dane)
```

### Wstępne przetworzenie 
```{r pressure, echo=FALSE}
dane$CLAIM_FLAG <- as.factor(dane$CLAIM_FLAG)
dane$HOMEKIDS <- as.factor(dane$HOMEKIDS)
dane$PARENT1 <- as.factor(dane$PARENT1)
dane$MSTATUS <- as.factor(dane$MSTATUS)
dane$GENDER <- as.factor(dane$GENDER)
dane$EDUCATION <- as.factor(dane$EDUCATION)
dane$OCCUPATION <- as.factor(dane$OCCUPATION)
dane$CLM_FREQ <- as.factor(dane$CLM_FREQ)
dane$REVOKED <- as.factor(dane$REVOKED)

dane$URBANICITY <- as.factor(dane$URBANICITY)
dane$RED_CAR <- as.factor(dane$RED_CAR)

dane$MVR_PTS_GRP <- 0
dane$MVR_PTS_GRP[dane$MVR_PTS < 6] <- 1
dane$MVR_PTS_GRP[(dane$MVR_PTS > 5) & (dane$MVR_PTS < 11)] <- 2
dane$MVR_PTS_GRP[dane$MVR_PTS > 10] <- 3
dane$MVR_PTS_GRP <- as.factor(dane$MVR_PTS_GRP)


##Ad. model 4 - Nisko-wykwalifikowani vs wysoko wykfalifikowani
dane$OCCUPATION_GRP <- 0

dane$OCCUPATION_GRP[(dane$OCCUPATION=="Blue Collar") | 
                     (dane$OCCUPATION=="Home Maker") | 
                     (dane$OCCUPATION=="Home Maker") | 
                      (dane$OCCUPATION=="Student") ] <- 0

dane$OCCUPATION_GRP[(dane$OCCUPATION=="Clerical") | 
                    (dane$OCCUPATION=="Doctor") | 
                    (dane$OCCUPATION=="Lawyer") | 
                    (dane$OCCUPATION=="Manager") | 
                    (dane$OCCUPATION=="Professional")] <- 1

dane$OCCUPATION_GRP <- as.factor(dane$OCCUPATION_GRP)

dane <- na.omit(dane)
dane$AGE_tr <-(dane$AGE - median(dane$AGE))**2


## hOME VAL
dane$HOME_VAL_D <- 0
dane$HOME_VAL_D[dane$HOME_VAL  == 0] <-0
dane$HOME_VAL_D[dane$HOME_VAL != 0] <- 1
dane$HOME_VAL_D <- as.factor(dane$HOME_VAL_D)



summary(dane)
#
#cdplot(dane$INCOME, dane$CLAIM_FLAG, xlab = "dochód", ylab = "zadowolenie")
sapply(dane, typeof)
```


### Weryfikacja współlniowości
Weryfikacja współlino
Zmienne porządkowe - Spearman rank correlation coefficient (ordinal variables)
Nominalne - chi-square test (nominal variables)
#WSPÓŁINIOWOŚĆ - OCCUPATION_GRP - INCOME ?

```{r}
# Zmienne ciągłe

#chart.Correlation(dane[,c('INCOME', 'HOME_VAL', 'CLM_AMT','OLDCLAIM', 'BLUEBOOK','CAR_AGE')], histogram=TRUE, pch=9)

## Wspołliniowość zmiennych porzadkowych - rank spearman correlation
#cor.test(dane$INCOME, dane$MVR_PTS_GRP, method = 'spearman')
```

### Podział na dwa zbiory - treningowy i uczący.
Za pomocą generatora liczb w rozkładzie jednorodnym, losujemy 70% wszystkich rekordów tabeli i przypisujemy je do zestawu treningowe.
Pozostałe 30% zostaje przypisanych do zestawu testowego, który posłuży do ewaluacji skuteczności naszego modelu.
Po przeprowadzeniu podziału, weryfikujemy czy balans klas został zachowany w odniesieniu do oryginalnego zestawu danych.
```{r}
# Losowanie na wczesnym etapie, Podział na 
n <- nrow(dane)
liczby_losowe <- sample(c(1:n), round(0.7*n), replace = FALSE)
dane_uczacy <- dane[liczby_losowe,]
dane_testowy <- dane[-liczby_losowe,]

# Przeliczenie 
table(dane_testowy$CLAIM_FLAG) / nrow(dane_testowy)
table(dane_uczacy$CLAIM_FLAG) / nrow(dane_uczacy)
```
### Analiza danych pod kątem wystąpienia szkody / kolizji drogowej

**Pierwsze wnioski i hipotezy:**
- Zamożni rzadziej powodują wypadki, ale tylko do przedziału 22 018USD, dla kolejnych grup dochodowych liczba wypadkóW wzrasta \
- Mężczyzni częściej powodują wypadki (pytanie czy to istotna różnica) \
- Zdecydowanie więcej wypadków powodują osoby niebędące rodzicami \

- Osoby będące w dolnych grupach wiekowych powodują więcej kolizji, ta tendencja spada wraz z wiekiem aż do grupy 48-55lat i następnie wzrasta w grupach \

- Czy możemy sprawdzic czy największe prawdopodobieństwo wystąpeinia szkody zachodzi w przypadku podróży średnio-długich (45-60min) \

- Osoby, które otrzymały w przeszłości punkty karne, zdecydowanie częściej są uczestnikami kolizji drogowych. \ 

- Widoczna jest również zależność pomiędzy wiekiem samochodu a częstościa występowania zdarzenia,wraz z wiekiem samochodu, maleje szansa na udział kolizji drogowej. \ 

- Studenci i osoby nisko wykwalifikowane rzadziej biorą udział w kolizjach drogowych, może podział na dwie grupy ?

Zatem w procesie

#### Iteracyjne budowanie
```{r}
#select_if(dane, is.numeric)
cols <- as.vector(colnames(dane[,-c(26,23)]))

istotne = list()
for (c in cols[3:length(cols)]){
  
  if (c != 'CLAIM_FLAG'){
  
    m <- glm(as.formula(paste('CLAIM_FLAG', "~", c)), data = dane_uczacy, family = binomial)
    w_test <- waldtest(m)
  
  if (w_test$`Pr(>F)`[2] < 0.05){
      print(paste('istotna',c ,'pvalue:', format(w_test$`Pr(>F)`[2],  scientific = TRUE))[1])  
      #istotne <- append(istotne, c)
  } else{
      print(paste('nieistotna',c,'pvalue:', round(w_test$`Pr(>F)`[2], 2) ))
      #print(summary(m)$coefficients)
  }
  }
}

```
W iteracyjnej weryfikacji istotności zmiennych, większość zmiennych okazała się istotna.
Wśród cech nie mających wpływu na wystąpienie kolizji wyróżniamy płeć, kolor czerwony samochodu, wartość szkody.
Pozostałe (istotne) zmienne posłużą w budowaniu modelu. Oprócz kryterióW jakości modelu, cechy dobierane są w oparciu o dostępną wiedzę i doświadczenie. <br />


#### Proces budowania kolejnych zmiennych
### Model 1 - dochód
W pierwszym modelu stawiamy hipotezę, że istnieje zależność pomiędzy wzrostem dochodu a liczba kolizji.
```{r}
m1 <- glm(CLAIM_FLAG~INCOME, data = dane_uczacy, family = binomial)
summary(m1)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_1$, wnioskujemy, że zachodzi odwrotna zależność pomiędzy dochodem a szansą wystąpienia kolizji(Destymulanta).


### Model 2 - liczba przepracowanych lat w miejscu pracy
W drugim modelu stawiamy hipotezę, że istnieje zależność pomiędzy liczbą przepracowanych lat a liczba kolizji.
Czy 
```{r}
m2 <- glm(CLAIM_FLAG ~ INCOME + YOJ, data = dane_uczacy, family = binomial)
summary(m2)

```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_1$, wnioskujemy, że nie występuje istotna zależność pomiędzy liczbą przepracowanych lat a szansą wystąpienia kolizji w modelu ze zmienną dochód.
Parametr strukturalny *YOI*  zweryfikowany testem Walda jest nieistotny statystycznie modelu m2.

### Model 3 - fakt bycia samotnym rodzicem
W trzecim modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia samotnym rodzicem a zwiększonym ryzykiem udziału w kolizji.
Zmienna *PARENT1* jest zmienną dychotomicza, więc weryfikujemy tylko czy osoba jest rodzicem, czy też nie.<br/>

```{r}
m3 <- glm(CLAIM_FLAG~INCOME+PARENT1, data = dane_uczacy, family = binomial)
summary(m3)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_3$, wnioskujemy, że zachodzi odwrotna zależność pomiędzy faktem bycia samotnym rodzicem a szansą wystąpienia kolizji. Jeżli ktoś jest rodzicem, to zachodzi mniejsza szansa, że kierowca spowoduje kolizję <br/>.


### Model 4 - wiek
W czwartym modelu stawiamy hipotezę, że istnieje zależność pomiędzy wiekiem a liczba kolizji.
Zmienna *AGE* jest zmienną ilościową, jednak obserwujemy, że zarówno młodsi jak i starsi biorą udział w większej liczbie kolizji. 
Jednak bierzemy pod uwagę, że część samochodow moze byc w rzeczywistosci zarejestrowana na osoby starsze ale uzytkowana przez młodych - którzy powodują kolizje <br/>
Z tego powodu zmienną wiek przekształciliśmy $y'=(y-\overline{y})^2$.
```{r}
m4 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr, data = dane_uczacy, family = binomial)
summary(m4)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_2$, wnioskujemy, że zachodzi zależność pomiędzy syntentyczną zmienną odległości względem wartości środkowej rozkładu wieku a szansą wystąpienia kolizji . <br/>


### Model 5 - wartość domu -> fakt posiadania domu
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy wartością domu a liczba kolizji.
Ponieważ w 30% wszystkich rekordów wartość ta wynosi 0, zmienną ilościową zamieniliśmy na nominalną dychotomiczną (*HOME_VAL_D*) mówiącą o fakcie posiadania domu.

```{r}
m5 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D, data = dane_uczacy, family = binomial)
summary(m5)
```
```{r}
summary(m4)$aic - summary(m5)$aic
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_5$, wnioskujemy, że zachodzi  odwrotna zależność pomiędzy faktem posiadania domu a szansą wystąpienia kolizji. Zmienna **HOME_VAL_D** obniża wartość kryterium informacyjnego Akaike od 48.45. <br/>


### Model 6 - stan cywilny
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia małżenstwie a szansą zaistnienia kolizji.
Zmienna **MSTATUS** jest zmienną dychotomiczną.

```{r}
m6 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+MSTATUS, data = dane_uczacy, family = binomial)
summary(m6)
```
```{r}
summary(m5)$aic - summary(m6)$aic
```

**Wniosek** <br/>
Analizując parametr strukturalny $\beta_6$, wnioskujemy, że nie zachodzi istotna zależność pomiędzy faktem bycią małżonkiem a szansą wystąpienia kolizji.<br/>


### Model 7 - użytkowanie prywatne/komercyjne samochodu
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia małżenstwie a szansą zaistnienia kolizji.
Zmienna **CAR_USE** jest zmienną dychotomiczną.

```{r}
m7 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE, data = dane_uczacy, family = binomial)
summary(m7)
```
```{r}
summary(m5)$aic - summary(m7)$aic
```
**Wniosek**
Zmienna MSTATUS powoduje utrate istotnosci wyrazu wolnego.
Zmienna **CAR_USE** nie zostaje włączona do modelu, jej właczenie pozwala na obniżenie kryterium informacyjnego o 152.62 jednostek.

### Model 8 - Cena samochodu
```{r}
m8 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+BLUEBOOK, data = dane_uczacy, family = binomial)
summary(m8)
```
```{r}
summary(m7)$aic - summary(m8)$aic
```

**Wniosek**
Zmienna BlueBook nie poprawia dopasowanie naszego modelu, podwyższając wartość kryterium informacyjnego Akaike 145.51 jednostek.
Zmienna bluebook nie zostaje włączona do modelu.


### Model 9 - liczba lat jako klient
```{r}
m9 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+TIF, data = dane_uczacy, family = binomial)
summary(m9)
```

```{r}
summary(m8)$aic - summary(m9)$aic
```
**Wniosek**
Zmienna TIF poprawia nasz model zmniejszając wartość kryterium informacyjnego Akaike o 38.47.
Parametr strukturalny $\beta_9$zachowuje wysoki poziom istotności.
Zmienna TIF zostaje włączona do modelu.


### Model 10 - typ samochodu
Typ samochodu wiąże się z jego gabarytami, widocznością ciemnych pól widzenia i zakładamy, że może wypływać na zwiększoną szansę udziału w kolizji.
```{r}
m10 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE, data = dane_uczacy, family = binomial)
summary(m10)
```
```{r}
summary(m9)$aic - summary(m10)$aic
```
**Wniosek**
Ze względu na to, że zmienna CAR_TYPE znacznie obniża wartość kryterium informacyjnego, decydujemy o włączaniu jej do modelu.
Zmienna obniża wartość kryterium informacyjnego Akaike o 233.37.

### Model 11 - odebranie prawa jazdy w ciagu ostatnich 7 lat.
Weryfikacja czy fakt odebrania prawa jazdy zwiększa szanse na spowodowanie / udział w kolizji

```{r}
m11 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE+REVOKED, data = dane_uczacy, family = binomial)
summary(m11)
```
```{r}
summary(m10)$aic - summary(m11)$aic
```

**Wniosek**
Ze względu na to, że zmienna REVOKED znacznie podwyższa wartość kryterium informacyjnego, decydujemy o nie włączaniu jej do modelu.

### Model 12 - wiek samochodu
```{r}
m12 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE+REVOKED+CAR_AGE, data = dane_uczacy, family = binomial)
summary(m12)
```
```{r}
summary(m11)$aic - summary(m12)$aic

```
**Wnioski**
Parametr wieku samochodu jest istotny statystycznie jednak wprowadzenie go do modelu tylko nieznacznie obniża wartość kryterium informacyjnego Akaike o 132.45 jednostek. W rezultacie nie zostaje włączony do modelu.

### Model 13 -jednostka osadnicza
Zagęszczenie, skomplikowanie sieci dróg oraz intensywność ruchu samochodowego ma bezpośrednio wpływ na ryzyko zajścia sytuacji kolizyjnych w ruhu drogowym.
```{r}
m13 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE+REVOKED+URBANICITY, data = dane_uczacy, family = binomial)
summary(m13)
```
```{r}
summary(m11)$aic - summary(m13)$aic

```
**Wniosek**
Zmienna charakteryzująca jednostke osadniczą pozwoli
Wykorzystanie zmiennej charakteryzującej jednostkę osadniczą pozwoliło uzyskać model, który uzyskał wartość kryterium Akaike o 359 punktów niższą względem najlepszego dotychczasowego modelu.


### Model 14 -  typ zatrudnienia
Zakładamy, że osoby zatrudniony w zawodach wymagających wysokich kompetencji.
```{r}
m14 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE+REVOKED+OCCUPATION_GRP, data = dane_uczacy, family = binomial)
summary(m14)
```

```{r}
summary(m13)$aic - summary(m14)$aic
```
**Wniosek**
Zmienna pogarsza nasz model itd, jutro skoncze.

### Model 15 -  typ zatrudnienia
```{r}
m15 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE+REVOKED+KIDSDRIV, data = dane_uczacy, family = binomial)
summary(m15)
```

```{r}
summary(m13)$aic - summary(m15)$aic
```
**Wniosek**
Zmienna pogarsza nasz model itd, jutro skoncze.


### Model 16 -  liczba dzieci
```{r}
m16 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE+BLUEBOOK+TIF+CAR_TYPE+REVOKED+HOMEKIDS, data = dane_uczacy, family = binomial)
summary(m16)
```

```{r}
summary(m13)$aic - summary(m16)$aic
```
**Wniosek**
Zmienna pogarsza nasz model itd, jutro skoncze.


### Interakcje



# Najlepszy - najgorszy
```{r}
summary(m1)$aic - summary(m13)$aic
```
### Ocena 
```{r}

report <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(report) <- c('model','kryterium_AIC', 'McFadden', 'Cragg_Uhler')

for (i in seq(1, 14, 1)){
  print(i)
  mname <-paste('m', i, sep="")
  model = eval(parse(text = mname))
  
  kryterium_AIC <- c(model$aic)
  McFadden<-pR2(model)[4]
  Cragg_Uhler<-pR2(model)[6]
  report[i,] <- c(mname,kryterium_AIC, McFadden, Cragg_Uhler)
}

round(report, 3)



```
### Test i ewaluacja finalnego modelu na danych 
```{r}
pred <- predict(m13, dane_testowy)

pred_y <- as.numeric(pred > 0 )
true_y <- as.numeric(dane_testowy$CLAIM_FLAG)-1

# wskazania prawdziwie pozytywne
true_pos <- (true_y == 1) & (pred_y == 1)
# wskazania prawdziwie negatywne
true_neg <- (true_y == 0) & (pred_y == 0)
#wskazania fałszywie pozytywne
false_pos <- (true_y == 0) & (pred_y == 1)
#wskazania fałszywie negatywne
false_neg <- (true_y==1)&(pred_y==0)

```


### Dokładność
Wyznaczenie wartości najpopularniejszej miary skuteczności modelu logitowego.


### Macierz pomyłek

```{r}
conf_mat <- matrix(c(sum(true_pos), sum(false_pos),
                   sum(false_neg), sum(true_neg)), 2, 2)

colnames(conf_mat) <-c('yhat = 1', 'yhat = 0')
rownames(conf_mat) <- c('y = 1', 'y = 0')

conf_mat

```
### Miary na bazie macierzy pomyłek
```{r}
accuracy <- (sum(true_pos) + sum(true_neg)) / (length(pred))
accuracy

precision <- conf_mat[1, 1] / sum(conf_mat[,1])
precision

specifity <- conf_mat[1, 1] / sum(conf_mat[,1])
specifity

ppv <- 100*conf_mat[1,1]/(conf_mat[1,1]+ conf_mat[1,2])
npv <- 100*conf_mat[2,2]/(conf_mat[2,1]+ conf_mat[2,2])

df <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(df) <- c("dokładność", "czułość", 'specyficzność', 'PPV', 'NPV')
df[1,] = c(accuracy, precision, specifity,ppv,npv)
df
```

### Krzywa ROC

```{r}
idx <- order(-pred)
recall <- cumsum(true_y[idx]==1)/sum(true_y == 1)
specifity <- (sum(true_y == 0 ) - cumsum(true_y[idx] == 0)) / sum(true_y == 0)

roc_df <- data.frame(recall = recall, specifity=specifity)

ggplot(roc_df, aes(x=specifity, y=recall)) +
  geom_line(color='blue') +
  scale_x_reverse(expand = c(0, 0))+
  scale_y_continuous(expand=c(0,0))+
  geom_line(data=data.frame(x=(0:100)/100), aes(x=x, y=1-x),linetype='dotted',color='red')

```
### AUC - Area Under Curve
```{r}
sum(roc_df$recall[-1] * diff(1 - roc_df$specifity))
```

