---
title: "Regresja_Logistyczna"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}

library("readxl")
library("car") # funkcja vif()
library("ggplot2") # wykresy - funkcja ggplot()
library("lmtest") # testy diagnostyczne modeli lm

library("PerformanceAnalytics")
library("ggplot2") # wykresy - funkcja ggplot()
library("pscl") #pseudo-R2 funkcja pR2()
library("pROC") #funkcje roc, auc
set.seed(1257) #set.seed(NULL) --> usunięcie "ziarna"

knitr::opts_chunk$set(echo = TRUE)
```

## Wstep
to do list: \ 
 - interakcje -
 - część samochodow moze byc w rzeczywistosci zarejestrowana na osoby starsze ale uzytkowana przez młodych - którzy powodują kolizje
 -Jeszcze analizuje ale mysle, ze takie zalozenie ma sens, opieramy model na: dochodzie, fakcie bycia rodzicem, wieku i uprzednio otrzymanych punktach karnych. Pozostałe zmienne są pochodnymi tych cech.

### Wczytanie danych
```{r}
dane <- read.csv("C:/Users/dominikm/Desktop/Modele_Parametryczne_Projekt/Modele_Parametryczne/dane/LR_dane_treningowe_testowe.csv")
summary(dane)
```

### Wstępne przetworzenie 
```{r pressure, echo=FALSE}
dane$CLAIM_FLAG <- as.factor(dane$CLAIM_FLAG)
dane$KIDSDRIV <- as.factor(dane$KIDSDRIV)
dane$HOMEKIDS <- as.factor(dane$HOMEKIDS)
dane$PARENT1 <- as.factor(dane$PARENT1)
dane$MSTATUS <- as.factor(dane$MSTATUS)
dane$GENDER <- as.factor(dane$GENDER)
dane$EDUCATION <- as.factor(dane$EDUCATION)
dane$OCCUPATION <- as.factor(dane$OCCUPATION)
dane$CLM_FREQ <- as.factor(dane$CLM_FREQ)
dane$REVOKED <- as.factor(dane$REVOKED)

dane$URBANICITY <- as.factor(dane$URBANICITY)
dane$RED_CAR <- as.factor(dane$RED_CAR)

dane$MVR_PTS_GRP <- 0
dane$MVR_PTS_GRP[dane$MVR_PTS < 6] <- 1
dane$MVR_PTS_GRP[(dane$MVR_PTS > 5) & (dane$MVR_PTS < 11)] <- 2
dane$MVR_PTS_GRP[dane$MVR_PTS > 10] <- 3
dane$MVR_PTS_GRP <- as.factor(dane$MVR_PTS_GRP)


##Ad. model 4 - Nisko-wykwalifikowani vs wysoko wykfalifikowani
dane$OCCUPATION_GRP <- 0

dane$OCCUPATION_GRP[(dane$OCCUPATION=="Blue Collar") | 
                     (dane$OCCUPATION=="Home Maker") | 
                     (dane$OCCUPATION=="Home Maker") | 
                      (dane$OCCUPATION=="Student") ] <- 0

dane$OCCUPATION_GRP[(dane$OCCUPATION=="Clerical") | 
                    (dane$OCCUPATION=="Doctor") | 
                    (dane$OCCUPATION=="Lawyer") | 
                    (dane$OCCUPATION=="Manager") | 
                    (dane$OCCUPATION=="Professional")] <- 1

dane$OCCUPATION_GRP <- as.factor(dane$OCCUPATION_GRP)

dane <- na.omit(dane)
dane$AGE_tr <-(dane$AGE - median(dane$AGE))**2


## hOME VAL
dane$HOME_VAL_D <- 0
dane$HOME_VAL_D[dane$HOME_VAL  == 0] <-0
dane$HOME_VAL_D[dane$HOME_VAL != 0] <- 1
dane$HOME_VAL_D <- as.factor(dane$HOME_VAL_D)



summary(dane)
#
#cdplot(dane$INCOME, dane$CLAIM_FLAG, xlab = "dochód", ylab = "zadowolenie")
sapply(dane, typeof)
```


### Weryfikacja współlniowości
Weryfikacja współlino
Zmienne porządkowe - Spearman rank correlation coefficient (ordinal variables)
Nominalne - chi-square test (nominal variables)
#WSPÓŁINIOWOŚĆ - OCCUPATION_GRP - INCOME ?

```{r}
# Zmienne ciągłe

chart.Correlation(dane[,c('INCOME', 'HOME_VAL', 'CLM_AMT','OLDCLAIM', 'BLUEBOOK','CAR_AGE')], histogram=TRUE, pch=9)

## Wspołliniowość zmiennych porzadkowych - rank spearman correlation
#cor.test(dane$INCOME, dane$MVR_PTS_GRP, method = 'spearman')
```

### Podział na dwa zbiory - treningowy i uczący.
Za pomocą generatora liczb w rozkładzie jednorodnym, losujemy 70% wszystkich rekordów tabeli i przypisujemy je do zestawu treningowe.
Pozostałe 30% zostaje przypisanych do zestawu testowego, który posłuży do ewaluacji skuteczności naszego modelu.
Po przeprowadzeniu podziału, weryfikujemy czy balans klas został zachowany w odniesieniu do oryginalnego zestawu danych.
```{r}
# Losowanie na wczesnym etapie, Podział na 
n <- nrow(dane)
liczby_losowe <- sample(c(1:n), round(0.7*n), replace = FALSE)
dane_uczacy <- dane[liczby_losowe,]
dane_testowy <- dane[-liczby_losowe,]

# Przeliczenie 
table(dane_testowy$CLAIM_FLAG) / nrow(dane_testowy)
table(dane_uczacy$CLAIM_FLAG) / nrow(dane_uczacy)
```
### Analiza danych pod kątem wystąpienia szkody / kolizji drogowej

**Pierwsze wnioski i hipotezy:**
- Zamożni rzadziej powodują wypadki, ale tylko do przedziału 22 018USD, dla kolejnych grup dochodowych liczba wypadkóW wzrasta \
- Mężczyzni częściej powodują wypadki (pytanie czy to istotna różnica) \
- Zdecydowanie więcej wypadków powodują osoby niebędące rodzicami \

- Osoby będące w dolnych grupach wiekowych powodują więcej kolizji, ta tendencja spada wraz z wiekiem aż do grupy 48-55lat i następnie wzrasta w grupach \

- Czy możemy sprawdzic czy największe prawdopodobieństwo wystąpeinia szkody zachodzi w przypadku podróży średnio-długich (45-60min) \

- Osoby, które otrzymały w przeszłości punkty karne, zdecydowanie częściej są uczestnikami kolizji drogowych. \ 

- Widoczna jest również zależność pomiędzy wiekiem samochodu a częstościa występowania zdarzenia,wraz z wiekiem samochodu, maleje szansa na udział kolizji drogowej. \ 

- Studenci i osoby nisko wykwalifikowane rzadziej biorą udział w kolizjach drogowych, może podział na dwie grupy ?

Zatem w procesie

#### Iteracyjne budowanie
```{r}
#select_if(dane, is.numeric)
cols <- as.vector(colnames(dane[,-c(26,23)]))

istotne = list()
for (c in cols[6:length(cols)]){
  #print(c)
  m <- glm(as.formula(paste('CLAIM_FLAG', "~", c)), data = dane_uczacy, family = binomial)
  
  w_test <- waldtest(m)
  
  if (w_test$`Pr(>F)`[2] < 0.05){
      print(paste('istotna',c ,'pvalue:', format(w_test$`Pr(>F)`[2],  scientific = TRUE))[1])  
      #istotne <- append(istotne, c)
  } else{
      print(paste('nieistotna',c,'pvalue:', round(w_test$`Pr(>F)`[2], 2) ))
      #print(summary(m)$coefficients)
  }
}

```
W iteracyjnej weryfikacji istotności zmiennych, większość zmiennych okazała się istotna.
Wśród cech nie mających wpływu na wystąpienie kolizji wyróżniamy płeć, kolor czerwony samochodu, wartość szkody.
Pozostałe (istotne) zmienne posłużą w budowaniu modelu. Wśród kryterióW jakości modelu, cechy dobierane są w oparciu o dostępną wiedzę i doświadczenie. <br />


#### Proces budowania kolejnych zmiennych
### Model 1 - Dochód
W pierwszym modelu stawiamy hipotezę, że istnieje zależność pomiędzy wzrostem dochodu a liczba kolizji.
```{r}
m1 <- glm(CLAIM_FLAG~INCOME, data = dane_uczacy, family = binomial)
summary(m1)

```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_1$, wnioskujemy, że zachodzi odwrotna zależność pomiędzy dochodem a szansą wystąpienia kolizji(Destymulanta).


### Model 2 - Liczba przepracowanych lat w miejscu pracy
W drugim modelu stawiamy hipotezę, że istnieje zależność pomiędzy liczbą przepracowanych lat a liczba kolizji.
Czy 
```{r}
m2 <- glm(CLAIM_FLAG ~ INCOME + YOJ, data = dane_uczacy, family = binomial)
summary(m2)

```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_1$, wnioskujemy, że nie występuje istotna zależność pomiędzy liczbą przepracowanych lat a szansą wystąpienia kolizji w modelu ze zmienną dochód.
Parametr strukturalny *YOI*  zweryfikowany testem Walda jest nieistotny statystycznie modelu m2.

### Model 3 - fakt bycia rodzicem
W trzecim modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia rodzicem liczba kolizji.
Zmienna *PARENT1* jest zmienną dychotomicza, więc weryfikujemy tylko czy osoba jest rodzicem, czy też nie.<br/>

```{r}
m3 <- glm(CLAIM_FLAG~INCOME+PARENT1, data = dane_uczacy, family = binomial)
summary(m3)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_3$, wnioskujemy, że zachodzi odwrotna zależność pomiędzy faktem bycia rodzicem a szansą wystąpienia kolizji. Jeżli ktoś jest rodzicem, to zachodzi mniejsza szansa, że kierowca spowoduje kolizję <br/>.


### Model 4 - wiek
W czwartym modelu stawiamy hipotezę, że istnieje zależność pomiędzy wiekiem a liczba kolizji.
Zmienna *AGE* jest zmienną ilościową, jednak obserwujemy, że zarówno młodsi jak i starsi biorą udział w większej liczbie kolizji. 
Jednak bierzemy pod uwagę, że część samochodow moze byc w rzeczywistosci zarejestrowana na osoby starsze ale uzytkowana przez młodych - którzy powodują kolizje <br/>
Z tego powodu zmienną wiek przekształciliśmy $y'=(y-\overline{y})^2$.
```{r}
m4 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr, data = dane_uczacy, family = binomial)
summary(m4)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_2$, wnioskujemy, że zachodzi zależność pomiędzy syntentyczną zmienną odległości względem wartości środkowej rozkładu wieku a szansą wystąpienia kolizji . <br/>


### Model 5 - wartość domu -> fakt posiadania domu
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy wartością domu a liczba kolizji.
Ponieważ w 30% wszystkich rekordów wartość ta wynosi 0, zmienną ilościową zamieniliśmy na nominalną dychotomiczną (*HOME_VAL_D*) mówiącą o fakcie posiadania domu.

```{r}
m5 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D, data = dane_uczacy, family = binomial)
summary(m5)
```
```{r}
summary(m4)$aic - summary(m5)$aic
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_5$, wnioskujemy, że zachodzi  odwrotna zależność pomiędzy faktem posiadania domu a szansą wystąpienia kolizji. Zmienna **HOME_VAL_D** obniża wartość kryterium informacyjnego Akaike od 48.45. <br/>


### Model 6 - stan cywilny
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia małżenstwie a szansą zaistnienia kolizji.
Zmienna **MSTATUS** jest zmienną dychotomiczną.

```{r}
m6 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+MSTATUS, data = dane_uczacy, family = binomial)
summary(m6)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_6$, wnioskujemy, że nie zachodzi istotna zależność pomiędzy faktem bycią małżonkiem a szansą wystąpienia kolizji.<br/>


### Model 7 - 
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia małżenstwie a szansą zaistnienia kolizji.
Zmienna **CAR_USE** jest zmienną dychotomiczną.

```{r}
m7 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+CAR_USE, data = dane_uczacy, family = binomial)
summary(m7)
```
```{r}
summary(m5)$aic - summary(m7)$aic
```
**Wniosek**

[1] "istotna TRAVTIME pvalue: 5.425129e-07"
[1] "istotna CAR_USE pvalue: 5.353845e-28"
[1] "istotna BLUEBOOK pvalue: 2.554077e-14"
[1] "istotna TIF pvalue: 3.066795e-09"
[1] "istotna CAR_TYPE pvalue: 4.643908e-20"
[1] "nieistotna RED_CAR pvalue: 0.48"
[1] "istotna OLDCLAIM pvalue: 4.806921e-23"
[1] "istotna CLM_FREQ pvalue: 4.713843e-78"
[1] "istotna REVOKED pvalue: 1.327e-28"
Warning: glm.fit: algorithm did not converge
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
[1] "nieistotna CLM_AMT pvalue: 0.99"
[1] "istotna CAR_AGE pvalue: 1.231955e-18"
[1] "istotna URBANICITY pvalue: 5.618925e-54"
[1] "istotna MVR_PTS_GRP pvalue: 5.363152e-32"
[1] "istotna OCCUPATION_GRP pvalue: 3.650535e-22"
[1] "istotna AGE_tr pvalue: 3.091067e-19"
[1] "istotna HOME_VAL_D pvalue: 3.678084e-30"




























### Model 7 - 
W piątym modelu stawiamy hipotezę, że istnieje zależność pomiędzy faktem bycia małżenstwie a szansą zaistnienia kolizji.
Zmienna **MSTATUS** jest zmienną dychotomiczną.

```{r}
m7 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+HOME_VAL_D+TRAVTIME, data = dane_uczacy, family = binomial)
summary(m7)
```

































### Model 5 - occupation - [nie wejdzie do modelu, ale musze to udowodnic najpierw]
W czwartym modelu stawiamy hipotezę, że istnieje zależność pomiędzy podejmowanym rodzajem zawodu a liczba kolizji.
Zmienna *OCCUPATION_GRP* jest zmienną dychotomicza, więc weryfikujemy tylko czy osoba wykonuje zawód wymagający wysokich kwalifikacji, czy też nie.<br/>

```{r}
m4 <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr+OCCUPATION_GRP, data = dane_uczacy, family = binomial)
summary(m4)
```
**Wniosek** <br/>
Analizując parametr strukturalny $\beta_3$, wnioskujemy, że wystąpienie kolizji<br/>

### Model
```{r}
m <- glm(CLAIM_FLAG~INCOME+PARENT1+AGE_tr, data = dane_uczacy, family = binomial)
summary(m)$coefficients

```
### Weryfikacja występowania interakcji


### Ewalucja jakości modelu
Istotność całego modelu weryfikuje się za pomocą **testu ilorazu wiarygodnodści**, którego hipotezy mają postać: <br/>
$H_0 : β_1 = β_2 = ... = β_k = 0$ <br/>
$H_1 :∃_{1j≤k≤j} ≤ β_{j} ≠ 0$ <br/>
Hipoteza zerowa mówi, że wszystkie parametry przy zmiennych objaśniających są zerami, to znaczy prawdziwy jest jedynie model z wyrazem wolnym. 


### Ewaluacja zbiorcza - TO DO
**Podstawowe miary oceny skutecznosci modelu regresji logistycznej**
Skuteczność wyprowadzonych modeli zweryfikowano w oparciu o poniższe miary:
$PP$ - wskazania prawdziwie pozytywne - poprawnie zaklasyfikowane z klasy pozytywnej (1) <br />
$FP$ - wskazania fałszywie pozytywne - niepoprawnie sklasyfkowane wskazania z klasy pozytywnej <br />
$FN$ - wskazania fałszywie negatywne - niepoprawnie wskazania klasy negatywnej <br/>
$PN$ - wskazania prawdziwie negatywne - poprawne wskazania klasy negatywnej <br/>

$Dokładność = \frac{PP+PN}{N}$ - Iloraz wskazań poprawnie sklasyfikowanych do wszystkich elementów. 
Ze względu na to, że dokładność nie odzwierciedla dobrze skuteczności modelu z danymi niezbalansowanymi, wykorzystano również
miary czułości i specyficzności.<br />
Czułość $= \frac{PP}{PP+FN}$ - określa udział przypadków prawidłowo zaklasyfikowanych wśród wszystkich objętych przewidywaniem pozytywnym. </br>

Specyficzność $= \frac{PN}{PN+FP}$
<br />

**Miary dopasowania R2** <br />
Pseudo-$R^2$ McFaddena<br />
Opiera się on na porównaniu modelu pełnego z modelem zredukowanym tylko dla wyrazu wolnego. Oblicza się go według wzoru: <br />
$R^2 = 1 - \frac{\sum_i (y_i - \beta x_i)^2}{\sum_i (y_i - \bar y)^2}$ <br />
W praktyce wartości $R^2$ McFaddena są niewielkie, bliższe 0 niż 1. 

Pseudo-$R^2$ Maddala<br />



```{r}
p<-0.5

##
ocena_modelu_dwum <- function(model) {
  kryterium_AIC <- c(model$aic)
  McFadden<-pR2(model)[4]
  Cragg_Uhler<-pR2(model)[6]
  ocena <- data.frame(kryterium_AIC, McFadden, Cragg_Uhler)
  return(ocena)
}

ocena_modelu_dwum(m1)

##
miary_pred <- function(model, dane, Y, p = 0.5) {
  tab <- table(obserwowane = Y, przewidywane = ifelse(predict(model, dane, type = "response") > p, 1, 0))
  ACC <- (tab[1,1]+tab[2,2])/sum(tab)
  ER <- (tab[1,2]+tab[2,1])/sum(tab)
  SENS <- tab[2,2] / (tab[2,2] + tab[2,1])
  SPECI <- tab[1,1] / (tab[1,1] + tab[1,2])
  PPV <- tab[2,2] / (tab[2,2] + tab[1,2])
  NPV <- tab[1,1] / (tab[1,1] + tab[2,1])
  #Proszę dodpisać pozostałe miary jakości predykcji
  miary <- data.frame(ACC, ER,SENS, SPECI, PPV, NPV)
  return(miary)
}


wyniki_miary_pred <- rbind(model_logit = miary_pred(model = m, dane = dane_testowy, Y = dane_testowy$CLAIM_FLAG, p))
wyniki_miary_pred

###
rocobj1 <- roc(m$y, m$fitted.values)
rocobj1_t <- roc(dane_testowy$CLAIM_FLAG, predict(m, dane_testowy, type = "response"))

###
plot(rocobj1, main = "krzywe ROC dla modelu logitowego", col="red")
lines(rocobj1_t, col="blue")

```
```{r}

#tab <- table(obserwowane = dane['CLAIM_FLAG'], przewidywane = ifelse(predict(m, dane, type = "response") > p, 1, 0))
#tab
```
**Reference** <br />
**Wykorzystanie modeli logitowych w analizie czynników aktywności zawodowej ludności**, Dominik ŚLIWICKI, Marek RĘKLEWSKI, 2006

